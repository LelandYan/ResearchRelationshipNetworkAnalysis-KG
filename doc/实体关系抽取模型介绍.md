大型的知识图谱需要依靠海量的实体和实体间关系继续支撑，类似于RDF三元组的关系的结构化的数据，但是这种大量的数据并没有大量的存在，虽然随着互联网的发展，已经存储了大量的结构化、半结构化和非结构的数据，但是这些数据并不能直接的进行使用，我们需要对这些数据进行处理。对于关系性数据库或者表格存储结构化的数据，我们可以简单的提取我们需要的实体间的关系，针对半结构化的数据，例如json和xml网络上的数据，我们需要通过包装器来提取我们需要的数据，然后将其转化为三元组的形式。最后对于非结构化的数据，文本数据，这里是最为困难的，我们需要通过文本的数据来提取我们需要的三元组的关系数据。

我们将原始数据分为结构化数据、半结构化数据和非结构化数据，根据不同的数据类型，我们采用不同的方法进行处理。

### 2.1 结构化数据处理

针对结构化数据，通常是关系型数据库的数据，数据结构清晰，把关系型数据库中的数据转换为RDF数据（linked data），普遍采用的技术是D2R技术。D2R主要包括D2R Server，D2RQ Engine和D2RRQ Mapping语言。

D2R Server 是一个 HTTP Server，它的主要功能提供对RDF数据的查询访问接口，以供上层的RDF浏览器、SPARQL查询客户端以及传统的 HTML 浏览器调用。 D2RQ Engine的主要功能是使用一个可定制的 D2RQ Mapping 文件将关系型数据库中的数据换成 RDF 格式。D2RQ engine 并没有将关系型数据库发布成真实的 RDF 数据，而是使用 D2RQ Mapping 文件将其映射成虚拟的 RDF 格式。该文件的作用是在访问关系型数据时将 RDF 数据的查询语言 SPARQL 转换为 RDB 数据的查询语言 SQL，并将 SQL 查询结果转换为 RDF 三元组或者 SPARQL 查询结果。D2RQ Engine 是建立在 Jena（Jena 是一个创建 Semantic Web 应用的 Java 平台，它提供了基于 RDF，SPARQL 等的编程环境）的接口之上。 D2RQ Mapping 语言的主要功能是定义将关系型数据转换成 RDF 格式的 Mapping 规则。

### 2.2 半结构化数据处理

半结构化数据，主要是指那些具有一定的数据结构，但需要进一步提取整理的数据。比如百科的数据，网页中的数据等。对于这类数据，主要采用包装器的方式进行处理。

包装器是一个能够将数据从HTML网页中抽取出来,并且将它们还原为结构化的数据的软件程序。网页数据输入到包装器中，通过包装器的处理，输出为我们需要的信息。

对于一般的有规律的页面，我们可以使用正则表达式的方式写出XPath和CSS选择器表达式来提取网页中的元素。但这样的通用性很差，因此也可以通过包装器归纳这种基于有监督学习的方法,自动的从标注好的训练样例集合中学习数据抽取规则,用于从其他相同标记或相同网页模板抽取目标数据。

### 2.3 非结构化数据处理

对于非结构化的文本数据，我们抽取的知识包括实体、关系、属性。对应的研究问题就有三个，一是实体抽取，也称为命名实体识别，此处的实体包括概念，人物，组织，地名，时间等等。二是关系抽取，也就是实体和实体之间的关系，也是文本中的重要知识，需要采用一定的技术手段将关系信息提取出来。三是属性抽取，也就是实体的属性信息，和关系比较类似，关系反映实体的外部联系，属性体现实体的内部特征。

非结构化数据的抽取问题，研究的人比较多，对于具体的语料环境，采取的技术也不尽相同。举个例子，比如关系抽取，有的人采用深度学习的方法，将两个实体，他们的关系，以及出处的句子作为训练数据，训练出一个模型，然后对于测试数据进行关系抽取，测试数据需要提供两个实体和出处的句子，模型在训练得到的已知关系中查找，得出测试数据中两个实体之间的关系。这是一种关系抽取的方法。还有人用句法依存特征，来获取关系，这种方法认为，实体和实体之间的关系可以组成主谓宾结构，在一个句子中，找出主谓关系和动宾关系，其中的谓词和动词如果是一个词，那么这个词就是一个关系。比如说“小明吃了一个苹果”，主谓关系是“小明吃”，动宾关系是“吃苹果”，那么就认为“吃”是一个关系。

当然，还有其它很多方法，可以在一定程度上实现实体抽取，关系抽取和属性抽取，效果可能会有差异，这需要在实践中测试和完善。

针对pdf的文章解析，难点在于无论使用哪种软件或硬件来查看它们，PDF文档的外观都相同。 不幸的是，该格式不保留与文本的逻辑结构有关的任何信息，例如单词，行，段落，枚举，节，节标题，甚至是文本块的阅读顺序。

CERMINE是一个综合的开源系统，用于以科学数字的形式从科学文章中提取结构化元数据。 该系统基于模块化的工作流程，其松散耦合的体系结构允许对单个组件进行评估和调整，可以轻松地改进和替换算法的独立部分，并有利于将来的体系结构扩展。 大多数步骤的实现都基于有监督和无监督的机器学习技术，从而简化了使系统适应新文档布局和样式的过程。 使用大型数据集对提取工作流进行的评估显示，大多数元数据类型均具有良好的性能，平均Fscore为77.5％。

CERMINE接受PDF格式的科学出版物作为输入。抽取算法检查文档的全部内容，并产生两种输出:文档元数据和参考书目。CERMINE的提取工作流由三条路径组成(图1)

![](C:\Users\27215\Desktop\my_notes\毕设\17.png)

（A）基本结构提取路径在输入上获取PDF文件，并产生其几何层次表示，该几何层次表示存储输入文档的整个文本内容以及与PDF文件中文本显示方式有关的几何特征。 更确切地说，该结构由页面，区域，线条，单词和字符以及它们的坐标和尺寸组成。 此外，所有元素的读取顺序都已设置，每个区域都用以下四个通用类别之一标记：元数据，引用，其他（B）元数据提取路径分析了几何层次结构的元数据部分，并从中提取了丰富的文档元数据集。（C） 参考书目提取路径分析标记为参考的部分结构。 结果是文档的已解析书目参考列表



Layout analysis：布局分析是整个工作流程的初始阶段。其目标是创建文档的层次结构，以保留输入文档的整个文本内容以及与该文本相关的功能显示在PDF文件中。布局分析包括以下步骤：

1.字符提取-从PDF文档中提取单个字符 

2.页面分割-将字符连接到单词，行和区域中

3.阅读顺序确定-计算所有结构级别的阅读顺序。

Content classification：内容分类的目标是确定文档中每个区域所扮演的角色。 这分两个步骤完成：初始区域分类和元数据区域分类。

初始分类的目标是用四个通用类之一标记每个区域：元数据（文档的元数据，例如标题，作者，摘要， 关键字等），引用（参考书目部分），正文（出版物的文本，部分，部分标题，等式，图形和表格，标题）或其他（致谢，利益冲突声明，页码等）。 

元数据区域分类是将所有元数据区域分类为特定的元数据类别：标题（文档标题），作者（作者姓名），隶属关系（作者隶属关系），编辑者（编辑者姓名），对应关系（地址） 和电子邮件），类型（文档中指定的类型，例如“研究文章”，“社论”或“案例研究”，摘要（文档摘要），关键字（文档中列出的关键字），bib_info（ 用于包含书目信息的区域，例如期刊名称，vo lume，issue，DOI等），日期（与文章发布过程相关的日期）。

分类器的实现方式相似。 他们都使用支持向量机。它们在目标区域标签，提取的特征和使用的SVM参数方面有所不同。使用Sects中介绍的相同步骤选择特征和SVM参数。



Metadata extraction：这一阶段的目的是分析标记为元数据的区域，并提取一组丰富的文档元数据信息，包括:标题，作者，隶属关系，关系作者从属关系，电子邮件地址，关系作者电子邮件摘要，关键词，期刊，数量，期刊，页面范围，年份和DOI。该阶段包括两个步骤：

1.元数据区域分类-将特定的元数据类分配给元数据区域

2.元数据提取-从标记区域中提取原子信息。使用一组基于启发式的简单规则来执行以下操作：–标记为抽象的区域是串联在一起的–通常指定的类型 在标题上方，如果需要的话，将其从标题区域中删除（基于类型的词典）； –作者，从属关系和关键字列表使用分隔符列表进行拆分； –从属关系基于索引和距离与作者相关联； –电子邮件地址 使用正则表达式从对应关系和隶属关系区域中提取，–电子邮件地址根据作者姓名与作者相关联，，–电子邮件地址使用正则表达式从附属机构和附属区域中删除 –如果文档中没有明确给出页码范围，我们也会尝试从每页的页码中检索，–日期使用正则表达式解析–根据正则从中提取日志，卷，期刊和DOI 表达式。



Bibliography extraction：参考文献提取的目的是从标记为参考的区域中提取出一个书目参考文献及其元数据（包括作者，标题，来源，卷，出版物，页数和年份）的列表。书目提取路径包括两个步骤：

1. 参考字符串提取-将参考区域的内容划分为单独的参考字符串
2. 引用解析-从引用字符串中提取元数据。



CERMINE是一个Java库和一个web服务(CERMINE .ceon.pl)，用于从包含学术出版物的PDF文件中提取元数据和内容。CERMINE是在华沙大学数学和计算模型跨学科中心开放科学中心用Java编写的。

CERMINE在很大程度上基于机器学习。 监督分类器是关键提取工作流部分（例如区域（块）分类或参考解析）的实施核心。

默认情况下，CERMINE包含用于分类的预定义模型，可以按原样使用。 但是，可以准备自定义模型并将其用于提取而不是默认模型。 当我们需要处理特定的文档布局或参考格式时，该系统的功能特别有用，而在用于学习默认模型的训练集中可能不存在这些格式。

本文档介绍了为两个任务准备自定义模型的过程：文档区域分类和参考解析，并提供有关如何在系统中包括自定义模型的信息。

CERMINE内部执行的最重要任务之一是为文档的文本片段分配角色。 该任务称为区域分类。 区域分类器是系统的核心，并且与页面分段器一起对元数据提取结果产生最大的影响。

区域是文档文本的一致片段，在几何上与周围的元素分开，并且没有分成几列。 CERMINE具有三个区域分类器：类别分类器将常规类别（元数据，主体，引用等）分配给区域，元数据分类器用特定的元数据类别标记元数据区域，主体分类器从全文中过滤掉表，图像和标签之类的片段。

分类器分析表示为特征向量的区域，这些区域是根据区域的文本内容，与区域序列相关的信息，文本格式和几何信息（尺寸，距离，位置）计算得出的。 通常，这些功能既可以反映区域的文本内容，又可以反映文本在PDF文件中的显示方式。

CERMINE包含三个区域分类模型，每个区域分类器一个。 使用来自GROTOAP2数据集的2500个文档对模型进行了训练。

GROTOAP2包含从PubMed Central Open Access Subset资源生成的13,210个文档。 数据集使用TrueViz格式存储文档。 TrueViz是一种基于XML的格式，它允许将文档表示为包含连续级别（页面，区域，线条，单词和字符）的几何层次结构。 TrueViz允许保留有关所有元素的文本内容，元素在其页面上的坐标，应读取元素的顺序以及区域标签的信息。



```
java -cp cermine-1.13.jar -path -outputs service
```



CERMINE: automatic extraction of structured metadatafrom scientific literatur
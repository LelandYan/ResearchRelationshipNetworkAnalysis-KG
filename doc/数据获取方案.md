# 数据获取方案

本项目中使用的所有的数据都是通过网络的爬虫从网络中获取的，其中爬虫方面主要可以分为两种类型，一种是文献数据库的爬虫，另一种是作者个人信息爬虫。下面将分别进行介绍：

## 文献数据库爬虫 

目前没有实时的收集的文章和作者信息的开源数据库，因此本文中需要借助各种文献数据获取我们需要的数据，这里我们只针对ACM Digital Library来说，ACM数字文库收录几乎大部分的期刊和会议投递的文章和作者的信息。而且大部分的数据都是可以通过解析html获得准确和严谨的书，非常适合作为我们的数据来源。ACM数字文库的搜索界面如下图：

![](imgs\27.png)

ACM数字文库可以通过关键词进行搜索与搜索关键词相关的文章，本文中通过搜索计算机、人工智能、大数据、知识图谱等关键词进行搜索得到文章数据，可以通过右上角框输入关键词。ACM数字文库是通过分页来进行数据展示的，可以通过页面上下方的两个框看出我们通过数据检索到数据的条数，和我们检索的每条数据的具体形式。其中包含了文章的标题、文章的作者、文章投递会议或者期刊、文章的摘要、文章的属于类别、文章的发表时间、文章的doi和文章的引用的数量等。

对文献数据库进行爬虫，首先需要人工设定种子URL，并设置参数页面展示的数据量、页面展示开始标志、页面爬取数据量的最大值。这样就可以通过不同参数的url依次访问ACM数据库中的数据，直到爬取数据的相应时间大于了我们设置的最大相应时间或者是已经爬取完毕所有搜索字段对应的数据。下面是关于文献爬虫的算法描述：

文献数据库爬虫算法描述如下：

**算法**：获取文献数据中数据

输入：种子URL队列

输出：文章标题、文章作者、文章发表年限、文章类型、文章的领域、文章url、文章的摘要和文章被引用的数量

（1）  定义待抓取链接队列urls，将种子URL放入改队列

（2）  定义已经获取链接列表has_urls

（3）  while(urls不为空):

（4）    获取urls中第一个链接，记为url

（5）    队列urls第一个链接出队

（6）    if 待抓取url不在has_urls列表中:

（7）      将url加入has_urls列表中

（8）      抓取url对应的页面

（9）      对抓取的页面进行解析

（10）    判断已经爬取数据数量是否已经大于关键词搜索数据总数量

（11）    if 小于:

（12）      修改页面展示开始标志

（13）      构造新的URL加入has_urls

（14）     end if

（15）  end if

（16）end while

从上述算法第（9）行可以看出，抓取的页面中的数据是全部html数据，包含了我们并不需要的数据，所以需要对获取的文本信息进行解析。这里我们使用的正则匹配和xpath解析方法相结合的方式，首先通过正则匹配的方式去我们不需要的标签以及及内容，例如script和sytle标签，然后我们通过xpath解析，使用xpath选择器选择我们需要的内容，并分别进行存储，它最大的优点是简洁快速。最后把抓取的信息整理成json格式，并存入mysql数据库中，方便后期处理。

在实际爬取数据的过程中，发现ACM文献数据非常容易封禁IP或者让超时访问，这里使用的是国内的免费ip代理，我们从国内免费的ip代理网址上搜集可使用ip，并形成ip代理池，可以解决被封IP或者超时访问的问题。

这里我们虽然已经有了从清华AMiner开源的数据，但是其数据并不是实时跟新和完整的，所以我们需要通过爬取ACM文献数据中的知识对我们收集的AMiner数据进行补充，特别是文章的摘要和作者的相关的信息。

### 作者个人信息爬虫 

当前我们已经搜集了关于作者、文章的一些信息，但是这些信息往往并不能展示作者最新的研究文章和获得荣誉，为了让用户更好的了解到作者的最新的研究文章和获得荣誉，我们通过爬取研究人员的主页来获取最新有关作者的信息，研究人员个人主页如下图：

![](imgs\24.png)

获得研究人员的主页数据后，我们可以解析html数据，通过标签我们可以分割出页面中的url、img、title和text等。我们通过不同标签中文本字数的比值获取我们需要的文本数据，而其他url、img和title可以通过html标签获取。在去除了无关的html的标签后，对text也就是正文进行短语级别的切分也就是通过标点符合和空格回车进行划分，分词后传入文本分类模型中可以得到文本的标签。

这个过程中，需要使用大量的正则匹配和BeautifulSoup解析，我们需要剔除冗余的html标签，然后针对科研人员的电子邮件进行正则匹配。对于最后text中文本分词，我们需要注意去除包含年限和标点符号，如果不去除将会影响我们后期的文本分类模型的效果。
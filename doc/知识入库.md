我们通过aminer和爬虫爬取的论文网站的ACM数据是一种具有结构化、分散的数据，我们需要对数据进行提取，将数据提取为三元组对应关系，形成标准化RDF三元组数据。

Aminer来源的数据：

数据集地址：https://www.aminer.cn/aminernetwork

该数据的内容包括论文信息，论文引文，作者信息和作者协作。 2092356篇论文和8024869之间的引用被保存在文件AMiner-Paper.rar中; 1712433位作者被保存在AMiner-Author.zip文件中，4258615位合作关系被保存在文件AMiner-Coauthor.zip中。

该文件AMiner-Paper.rar保存了论文信息和引文网络。

该文件AMiner-Paper.rar保存了作者信息。

该文件AMiner-Coauthor.zip保存了AMiner-Paper.rar中作者之间的协作网络。

| FileName            | **Node**      | *Number*       | *Size*  |
| ------------------- | ------------- | -------------- | ------- |
| AMiner-Paper.rar    | PaperCitation | 20923568024869 | 509 MB  |
| AMiner-Author.zip   | Author        | 1712433        | 167 MB  |
| AMiner-Coauthor.zip | Collaboration | 4258615        | 31.5 MB |

作者id和论文id的关系AMiner-Author2Paper.zip。第1列是索引，第2列是作者编号，第3列是论文编号，第4列是作者位置。连上补充数据一共4个数据集文件。

ACM文献数据库的数据：

数据集地址：https://dl.acm.org/action/doSearch?key+words

该数据的内容包括论文信息，包括了文章的标题、作者、发表时间、发表会议期刊名称、属于领域、文章所属doi、文章摘要和引用的数量。 11011篇文章以及相关的数据保存在mysql数据中。

![](imgs\10.png)

将两个数据进行整合去重后进行合并成csv文件。数据主要是Aminer数据为主，然后使用ACM论文数据对Aminer数据进行数据的补充，特别是关于作者发布文章的摘要、相关引用信息和发布年限。

author2csv.py脚本处理AMiner-Author.txt可以得到：

- e_affiliation: affiliation entity
- e_concept.csv: concept entity
- r_author2affiliation.csv: relation between author and affiliation
- r_author2concept.csv: relation between author and concept
- e_author.csv: author entity

author2paper2csv.py脚本处理AMiner-Author2Paper.txt可以得到：

- r_author2paper.csv: relation between author and paper

paper2csv.py脚本处理AMiner-Paper.txt可以得到：

- e_paper.csv: paper entity
- e_venue.csv: venue entity
- r_paper2venue.csv: relation between paper and venue
- r_citation.csv: relation between papers

coauthor2csv.py脚本处理AMiner-Coauthor.txt可以得到：

- r_coauthor.csv: relation between authors

汇总可以得到：

| 文件名                   | 类型 | 名称            | 数量       | 大小   |
| ------------------------ | ---- | --------------- | ---------- | ------ |
| e_author.csv             | 实体 | 作者            | 1,712,432  | 70M    |
| e_affiliation.csv        | 实体 | 作者隶属机构    | 624,750    | 54M    |
| e_concept.csv            | 实体 | 知识概念        | 4,055,686  | 131M   |
| e_paper.csv              | 实体 | 论文            | 2,092,355  | 1,495M |
| e_venue.csv              | 实体 | 期刊会议名      | 264,839    | 19M    |
| r_author2affiliation.csv | 关系 | 作者-机构       | 1,287,287  | 28M    |
| r_author2concept.csv     | 关系 | 作者-概念       | 14,589,981 | 339M   |
| r_author2paper.csv       | 关系 | 作者-论文       | 5,192,998  | 108M   |
| r_citation.csv           | 关系 | 引用            | 8,024,873  | 167M   |
| r_coauthor.csv           | 关系 | 合作者          | 4,258,946  | 120M   |
| r_paper2venue            | 关系 | 论文-期刊会议名 | 2,092,355  | 45M    |

以上共5个实体类型，6个关系类型。

至此，生成了Aminer学术社交网络知识图谱三元组数据。

Neo4j支持多种数据导入方式，既可以手动导入，也可以采用csv文件直接导入，本文的关系数据采用csv批量方式导入，首先需要将关系数据整理成csv格式，每一行表示一条关系。导入csv文件数据之前，必须将被导入文件放入neo4j安装目录下的import文件夹下才可以。

将上述11个csv文件放入Neo4j数据库的import文件夹中。

在Neo4j桌面端控制台一句一句执行下述CYPHER代码：

包含了实体节点导入、实体索引构建、关系导入、关系索引构建。

关系数据导入命令如下：

```python
USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///e_author.csv" AS line
CREATE (author:AUTHOR{authorID:toInt(line.authorID), authorName:toString(line.name), pc:toInt(line.pc), cn:toInt(line.cn), hi:toInt(line.hi), pi:toFloat(line.pi), upi:toFloat(line.upi)})

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///e_affiliation.csv" AS line
CREATE (affiliation:AFFILIATION{affiliationID:toInt(line.affiliationID), affiliationName:toString(line.name)})

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///e_concept.csv" AS line
CREATE (concept:CONCEPT{conceptID:toInt(line.conceptID), conceptName:toString(line.name)})

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///e_paper.csv" AS line
CREATE (paper:PAPER{paperID:toInt(line.paperID), paperTitle:toString(line.title), paperYear:toInt(line.year), paperAbstract:toString(line.abstract)})

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///e_venue.csv" AS line
CREATE (venue:VENUE{venueID:toInt(line.venueID), venueName:toString(line.name)})

CREATE INDEX ON: AUTHOR(authorID)

CREATE INDEX ON: AFFILIATION(affiliationID)

CREATE INDEX ON: CONCEPT(conceptID)

CREATE INDEX ON: PAPER(paperID)

CREATE INDEX ON: VENUE(venueID)
    
    
USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///r_author2affiliation.csv" AS line
MATCH (FROM:AUTHOR{authorID:toInt(line.START_ID)}), (TO:AFFILIATION{affiliationID:toInt(line.END_ID)})
MERGE (FROM)-[AUTHOR2AFFILIATION: AUTHOR2AFFILIATION{type:line.TYPE}]->(TO)

USING PERIODIC COMMIT 10000
LOAD CSV WITH HEADERS FROM "file:///r_author2concept.csv" AS line
MATCH (FROM:AUTHOR{authorID:toInt(line.START_ID)}), (TO:CONCEPT{conceptID:toInt(line.END_ID)})
MERGE (FROM)-[AUTHOR2CONCEPT: AUTHOR2CONCEPT{type:line.TYPE}]->(TO)

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///r_author2paper.csv" AS line
MATCH (FROM:AUTHOR{authorID:toInt(line.START_ID)}), (TO:PAPER{paperID:toInt(line.END_ID)})
MERGE (FROM)-[AUTHOR2PAPER: AUTHOR2PAPER{type:line.TYPE, author_pos:toInt(line.author_position)}]->(TO)

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///r_citation.csv" AS line
MATCH (FROM:PAPER{paperID:toInt(line.START_ID)}), (TO:PAPER{paperID:toInt(line.END_ID)})
MERGE (FROM)-[CITATION: CITATION{type:line.TYPE}]->(TO)

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///r_coauthor.csv" AS line
MATCH (FROM:AUTHOR{authorID:toInt(line.START_ID)}), (TO:AUTHOR{authorID:toInt(line.END_ID)})
MERGE (FROM)<-[COAUTHOR: COAUTHOR{type:line.TYPE, n_cooperation:toInt(line.n_cooperation)}]->(TO)

USING PERIODIC COMMIT 5000
LOAD CSV WITH HEADERS FROM "file:///r_paper2venue.csv" AS line
MATCH (FROM:PAPER{paperID:toInt(line.START_ID)}), (TO:VENUE{venueID:toInt(line.END_ID)})
MERGE (FROM)-[PAPER2VENUE: PAPER2VENUE{type:line.TYPE}]->(TO)


CREATE INDEX ON: AUTHOR(authorName)

CREATE INDEX ON: AFFILIATION(affiliationName)

CREATE INDEX ON: CONCEPT(conceptName)

CREATE INDEX ON: PAPER(paperTitle)

CREATE INDEX ON: VENUE(venueName)
```

导入neo4j数据库中后，得到该知识图谱数据图大小为23.45G，可以通过neo4j的desktop版本数据阅览功能出看到如下图，展示了node结点数量以及名称、结点之间关系以及名称和结点的属性以及名称：

![](imgs\11.png)
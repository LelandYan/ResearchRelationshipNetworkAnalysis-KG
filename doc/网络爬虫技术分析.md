随着网络技术的出现，网络数据已经达到了可观的水平。 互联网上有各种各样的大数据，互联网就是这些海量数据的集合。 但是，此数据不容易存储在本地数据库中以进行访问和处理。 人们在日常生活中使用的搜索工具（例如Google）只能为人们提供粗略的搜索结果，而不能提供准确的信息。 为了弥补一般搜索引擎的缺陷，出现了一种可以定向获取信息的搜索工具-垂直搜索引擎。 网络爬虫在收集网络数据中起着重要作用。 网络爬虫是一种计算机程序，可遍历超链接并为其编制索引。 作为垂直搜索引擎的核心部分，如何使爬行器更准确，更快速地获取信息已成为爬行器领域的重要研究方向，引起了国内外众多研究者的广泛关注。

网络爬虫（Web Crawl），又称为网络蜘蛛（Web Spider）或Web信息采集器[17]。它是搜索引擎的一个重要组成部分，可以自动的从网页中下载想要的内容。爬网程序主要包括下载器，信息提取器，调度程序和爬网队列。 调度程序将提供的种子URL进行下载，然后下载程序从Internet获取页面信息以查找并发送信息提取器，提取器根据从信息中提取的指令信息来获取信息和下一级URL，然后将下一级URL传递给等待队列，等待队列去繁重的URL提交，过滤和排序操作进入列表，直到待爬行URL集合为空或达到某个终止条件才结束爬虫程序。爬虫程序中根据实际需要，用于存储待爬行URL的数据结构可选择栈或队列，使用栈存储待爬行URL是web数据进行深度优先遍历，用队列则是进行广度优先遍历。爬虫的实现原理和过程如图1所示：

![](imgs\12.png)

因爬虫技术可以快速获取相关知识，在数据挖掘领域，网络爬虫是不可或缺的数据获取手段。但是网络爬虫同样也会给被爬虫网站的服务器造成极大的压力，大量的快速访问势必导致服务器存在宕机的危险，因此很多网站都采取了不同程度的反爬虫手段，保证网站后台的健壮性。另一方面，网络中大部分的页面其实是重复的，客户端和服务端脚本语言的使用导致指向相同页面的URL呈指数级增长。这些特征都给网络爬虫造成了一定的困难，主要体现在单位时间内获取的可用知识少、容易被服务器识别出爬虫程序导致自己的IP被禁止访问。

爬虫根据其不同的特点，可以分为一般网络爬虫、聚焦网络爬虫、增量网络爬虫、深层网络爬虫、并行网络爬虫（1）通用网络爬虫常用于商业领域，因此它的技术细节公开资料较少。一般是从一些种子URL扩充到整个web，一般的网络爬虫必须运行很长时间，并消耗大量的硬盘空间，而对于页面的顺序相对要求较低，通常采用并行工作方式[18]，搜索引擎和大型Web服务提供商的数据采集工作可以使用通用网络爬虫；例如，谷歌的PageRank算法从网络上250亿个文档中返回符合搜索条件的页面。（2）聚焦网络爬虫也称为主题网络爬虫，它会筛选页面，只爬行与主题有关的页面，相比其他类型网络爬虫，聚焦网络爬虫多了一个评价模块，用于给链接和内容打分，而且也节省了网络与硬件资源，适用于特定领域的信息获取；聚焦网络爬虫和一般网络爬虫之间的区别在于两个用于过滤Web链接的模块：网页决定模块和URL链接优先级排名模块以过滤网页。网页判断模块：当搜寻器爬行以获取特定内容时，网页 相关性评估器开始比较网页中的内容与预先指定的主题之间的相关性。 如果网页的相关性未达到先前设置的阈值，则会放弃该网页以保持获取网页的高精度•URL链接优先级排名模块：该模块主要用于比较相关度 在解析的URL和给定主题之间。 该模块根据链接内容的权限和链接的引用次数对链接进行优先级排序。 按优先级排序并删除优先级过低的链接（3）增量式网络爬虫是增量式的对已经下载的网页进行更新，即只爬行新产生或发生过变化的网页[17]。它的优点在于，可以保证爬取的页面都是新的，可以减少数据下载量。当然，其算法的复杂度和实现难度也会相应增加；增量网络爬虫主要分为以下三种情况：•具有新页面的网站，例如小说中的新章节，日常新闻等。方法：确定 优点和缺点：无法获取页面更改的内容，但是由于不需要爬网url来发送请求，因此服务器上的压力相对较小，更快， 方法：分析内容后，判断内容的这一部分之前是否已经爬取。优点和缺点：您可以感知每个页面的内容是否已更改，并且您 可以在页面上添加或更改内容，但是由于请求每个URL的速度相对较慢，并且网站服务器上的压力也相对较大•确定内容是否正确。 写入存储介质时，t已经存在（最终保护措施）。使用单个搜寻器进程很难检索所有Internet数据，因此必须并行执行搜寻器进程才能在最短的时间内完成搜寻器进程。（4）深层网络爬虫是爬行那些不可以通过静态链接访问的页面，比如一些要求用户注册后才可以发现的网页内容。深层网络爬虫可访问的数据是表层网页的几百倍，是互联网最大的信息资源。 （4）并行网络爬虫设计的主要目标是最大化并行性能并最小化并行消耗。 并行网络爬虫可以是嵌入式的也可以是分布式的。 并行分布式搜寻器可以通过局域网或广域网进行通信。 

本任务中所有的数据都是从开放的数据网站中获取的，获取的途径包括了清华开源知识图谱数据集Aminer、ACM文献数据库、学者的个人主页以及用户提供的pdf格式的文章数据。我们需要通过不同的网站和文献数据库进行编写不同的网路爬虫，针对我们需要大量获取数据的网站或者文献数据我们需要使用分布式异步可代理scrapy框架进行编写，这个网络爬虫属于增量加上并行网络爬虫。而对于作者的主页个人信息的，我们使用聚焦网络爬虫获取作者的主要上我们需要的全部信息，并针对抓取的数据进行预处理。所以针对我们实际情况，我们可以将我们的爬虫分为两个大类，文献数据库爬虫和作者个人信息爬虫。

[1]      孙立伟, 何国辉, 吴礼发. 网络爬虫技术的研究[J]. 电脑知识与技术, 2010, 06(15):4112-4115.

Summary of web crawler technology research